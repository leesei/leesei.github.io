---
title: Information Theory
description: ""
created: 2019-08-20
updated: 2025-05-01
tags:
  - comp/lang
---

Entropy in Information Theory is the measure of information in terms of uncertainty
= Number of binary questions we have to ask to determine the state

[The Story of Information Theory - YouTube](https://www.youtube.com/watch?v=rmBFaNgg4wk)
[Solving Wordle using information theory - YouTube](https://www.youtube.com/watch?v=v68zYyaEmEA)
[Intro to Information Theory | Digital Communication | Information Technology - YouTube](https://www.youtube.com/watch?v=_PG-jJKB_do)
[Information Theory & Coding - Professor Brailsford - Computerphile - YouTube](https://www.youtube.com/playlist?list=PLzH6n4zXuckpKAj1_88VS-8Z6yn9zX_P6)

[Berry's Paradox - An Algorithm For Truth - YouTube](https://www.youtube.com/watch?v=FDXf1XxCXAk)
